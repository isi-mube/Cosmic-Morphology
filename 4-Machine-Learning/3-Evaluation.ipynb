{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn, optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from utils import train # custom function to train the model\n",
    "\n",
    "# For evaluation metrics\n",
    "from sklearn.metrics import (\n",
    "    f1_score, recall_score, precision_score,\n",
    "    confusion_matrix, classification_report\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Check device (GPU or CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color: orange;\">Data Augmentation & Processing</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path = os.getcwd()\n",
    "current_path = os.path.dirname(current_path)\n",
    "data_dir = os.path.join(current_path, \"3-Train-Val-Test-Split\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 224 # ResNet50 expects 224x224 images\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(input_size),  # Random cropping and resizing\n",
    "        transforms.RandomHorizontalFlip(p=0.5),  # Flip images horizontally with 50% probability\n",
    "        transforms.RandomVerticalFlip(p=0.5),  # Flip images vertically with 50% probability (if plausible)\n",
    "        transforms.RandomRotation(degrees=45),  # Rotate images randomly within ±45 degrees\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Adjust brightness, contrast, etc.\n",
    "        transforms.RandomAffine(\n",
    "            degrees=15,  # Rotate within ±15 degrees\n",
    "            translate=(0.1, 0.1),  # Allow small translations (10% of image size)\n",
    "            scale=(0.9, 1.1),  # Allow small zoom in/out\n",
    "            shear=10  # Allow small shearing\n",
    "        ),\n",
    "        transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0)),  # Apply slight blurring\n",
    "        transforms.ToTensor(),  # Convert image to tensor\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Normalize for ResNet50\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(int(input_size * 1.1)),  # Resize slightly larger to allow for CenterCrop\n",
    "        transforms.CenterCrop(input_size),  # Crop to the target size\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(int(input_size * 1.1)),  # Resize slightly larger to allow for CenterCrop\n",
    "        transforms.CenterCrop(input_size),  # Crop to the target size\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color: orange;\">Data Loading</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_datasets = {\n",
    "    phase: datasets.ImageFolder(\n",
    "        os.path.join(data_dir, phase), \n",
    "        transform=data_transforms[phase]\n",
    "    )\n",
    "    for phase in ['train', 'val', 'test']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "batch_size = 64\n",
    "dataloaders = {\n",
    "    phase: DataLoader(\n",
    "        image_datasets[phase], \n",
    "        batch_size=batch_size, \n",
    "        shuffle=True if phase == 'train' else False,\n",
    "        num_workers=2\n",
    "    )\n",
    "    for phase in ['train', 'val', 'test']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['asteroid', 'comet', 'galaxy', 'nebula', 'planet', 'star']\n",
      "Dataset sizes: {'train': 1800, 'val': 600, 'test': 600}\n"
     ]
    }
   ],
   "source": [
    "# Dataset sizes and class names\n",
    "dataset_sizes = {phase: len(image_datasets[phase]) for phase in ['train', 'val', 'test']}\n",
    "class_names = image_datasets['train'].classes\n",
    "print(\"Classes:\", class_names)\n",
    "print(\"Dataset sizes:\", dataset_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color: orange;\">Hyperparameters</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler_step_size = 7\n",
    "scheduler_gamma = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color: orange;\">Transfer Learning</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50(weights=\"ResNet50_Weights.DEFAULT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all layers except the final fully connected layer\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the final layer to match the number of classes\n",
    "num_ftrs = model.fc.in_features\n",
    "num_classes = len(class_names)  # Number of classes in your dataset\n",
    "model.fc = nn.Linear(num_ftrs, num_classes)  # num_classes = 6 (as per dataset)\n",
    "model = model.to(device) # Move model to device (GPU or CPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color: orange;\">Hyperparameters</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss() # Loss function\n",
    "learning_rate = 1e-3 \n",
    "epochs = 20\n",
    "scheduler_step_size = 7\n",
    "scheduler_gamma = 0.1\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=learning_rate) # Optimizer\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=scheduler_step_size, gamma=scheduler_gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train the model for a few epochs with early stopping\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model, history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m(\n\u001b[1;32m      3\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m      4\u001b[0m     criterion\u001b[38;5;241m=\u001b[39mcriterion,\n\u001b[1;32m      5\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[1;32m      6\u001b[0m     scheduler\u001b[38;5;241m=\u001b[39mscheduler,\n\u001b[1;32m      7\u001b[0m     num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,  \u001b[38;5;66;03m# Reduced epochs for quick validation\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,  \u001b[38;5;66;03m# Stop early if no improvement in 2 epochs\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     min_delta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m  \u001b[38;5;66;03m# Minimum improvement to consider\u001b[39;00m\n\u001b[1;32m     10\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_model' is not defined"
     ]
    }
   ],
   "source": [
    "# Train the model for a few epochs with early stopping\n",
    "model, history = train_model(\n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    num_epochs=5,  # Reduced epochs for quick validation\n",
    "    patience=2,  # Stop early if no improvement in 2 epochs\n",
    "    min_delta=0.01  # Minimum improvement to consider\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_history(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
